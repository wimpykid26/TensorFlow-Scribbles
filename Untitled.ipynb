{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text classification using Tensorflow\n",
    "\n",
    "Basic Tensorflow model to predict text categories based on word2vec. Trained on 20newsgroup dataset from scikit using RELU. Better approach to be experimented further.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating data and passing it into Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = Counter()\n",
    "\n",
    "def get_word_to_index(vocab):\n",
    "    '''\n",
    "    Returns a hash of words and indexes in a sentence\n",
    "    '''\n",
    "    word_to_index = {}\n",
    "    for i,word in enumerate(vocab):\n",
    "        word_to_index[word] = i\n",
    "    \n",
    "    return word_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"comp.graphics\",\"sci.space\",\"rec.sport.baseball\"]\n",
    "newsgroup_train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "newsgroup_test = fetch_20newsgroups(subset='test', categories=categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for text in newsgroup_train.data:\n",
    "    for word in text.split(' '):\n",
    "        vocab[word.lower()] +=1\n",
    "\n",
    "for text in newsgroup_train.data:\n",
    "    for word in text.split(' '):\n",
    "        vocab[word.lower()] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2index = get_word_to_index(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting all words to vector arrays using frequency in vocabulary list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = len(vocab)\n",
    "def text_to_vector(text):\n",
    "    '''\n",
    "    Returns the vector array of corresponding vocabulary using of indexes of individual words\n",
    "    '''\n",
    "    layer = np.zeros(total_words, dtype=float)\n",
    "    for word in text.split(' '):\n",
    "        layer[word2index[word]] +=1\n",
    "    \n",
    "    return layer\n",
    "\n",
    "def category_to_vector(category):\n",
    "    y = np.zeros((3), dtype=float)\n",
    "    if category == 0:\n",
    "        y[0] = 1\n",
    "    elif category == 1:\n",
    "        y[1] = 1\n",
    "    else:\n",
    "        y[2] = 1\n",
    "        \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(df, i, batch_size):\n",
    "    '''\n",
    "    Returns np array of text vectors\n",
    "        df: dataframe to be converted to batches\n",
    "        i: number of batches\n",
    "        batch_size: singular batch size\n",
    "        \n",
    "    Single batch contains multiple layers of text vectors.\n",
    "    Test and train data contain numerous batches\n",
    "    '''\n",
    "    \n",
    "    batches = []\n",
    "    results = []\n",
    "    texts = df.data[i*batch_size, i*batch_size + batch_size]\n",
    "    results = df.target[i*batch_size, i*batch_size + batch_size]\n",
    "    \n",
    "    for text in texts:\n",
    "        batches.append(text_to_vector(text))\n",
    "    for result in results:\n",
    "        batches.append(text_to_vector(result))\n",
    "    \n",
    "    return np.array(batches), np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 100\n",
    "batch_size = 150\n",
    "display_step = 1\n",
    "\n",
    "#Network Parameters\n",
    "n_hidden_1 = 100      # 1st layer number of features\n",
    "n_hidden_2 = 100       # 2nd layer number of features\n",
    "n_input = total_words # Words in vocab\n",
    "n_classes = 3         # Categories: graphics, sci.space and baseball\n",
    "\n",
    "input_tensor = tf.placeholder(tf.float32,[None, n_input], name=\"Input\")\n",
    "output_tensor = tf.placeholder(tf.float32,[None, n_classes], name=\"Output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multilayer_perceptron(input_tensor, weights, biases):\n",
    "    layer_1_multiplication = tf.matmul(input_tensor, weights['h1'])\n",
    "    layer_1_addition = tf.add(layer_1_multiplication, biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1_addition)\n",
    "    \n",
    "    # Hidden layer with RELU activation\n",
    "    layer_2_multiplication = tf.matmul(layer_1, weights['h2'])\n",
    "    layer_2_addition = tf.add(layer_2_multiplication, biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2_addition)\n",
    "    \n",
    "    # Output layer \n",
    "    out_layer_multiplication = tf.matmul(layer_2, weights['out'])\n",
    "    out_layer_addition = out_layer_multiplication + biases['out']\n",
    "    \n",
    "    return out_layer_addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
